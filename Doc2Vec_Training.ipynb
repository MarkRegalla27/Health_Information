{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import re\n",
    "import os\n",
    "import codecs\n",
    "#from sklearn import feature_extraction\n",
    "import mpld3\n",
    "import sys\n",
    "import simplejson\n",
    "import json\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/numpy/lib/utils.py:95: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  warnings.warn(depdoc, DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/Users/markregalla/anaconda/lib/python2.7/site-packages/scipy/lib/_util.py:67: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Doc2Vec/Word2vec packages\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "import os\n",
    "import wikipedia\n",
    "import random\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Loop through many wikipedia pages\n",
    "Runs them through training model\n",
    "\n",
    "Wikipedia API guide:\n",
    "https://en.wikipedia.org/wiki/Special:ApiSandbox#action=query&prop=info&format=json&inprop=url&pageids=1000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempts: 259987  Sucesses: 50000\n",
      "50000\n",
      "CPU times: user 3h 23min 41s, sys: 8min 50s, total: 3h 32min 32s\n",
      "Wall time: 14h 10min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 44962         #i = 44962  (12-4-15 11:43 pm)\n",
    "counter = 9103   #counter = 9103 (12-4-15 11:43 pm)\n",
    "#good_id_list = [] #be sure only to initialize as empty list the first time\n",
    "#id_list = []      #use new list if you want to preserve good_id_list in memory\n",
    "\n",
    "while counter < 50000:   #number is limit of number of page ids to get\n",
    "    scrape_worked = False\n",
    "    #if i == 1000:\n",
    "    #    print 'went on too long'\n",
    "    #    break\n",
    "    page_id = 1000000 + i\n",
    "    \n",
    "    #try to scrape webpage.  Ignore if bad page error is returned from wikipedia\n",
    "    try:\n",
    "        r = requests.get('https://en.wikipedia.org/w/api.php?action=query&prop=info\\\n",
    "                &format=json&inprop=url&pageids=' + str(page_id))\n",
    "        rtext = r.text\n",
    "        jsontext = json.loads(rtext)\n",
    "        if jsontext['query']['pages'][str(page_id)]['ns'] == 0:\n",
    "            scrape_worked = True\n",
    "    except:\n",
    "        i += 1    \n",
    "    \n",
    "    if scrape_worked == True:\n",
    "        article = requests.get('https://en.wikipedia.org/?curid=' + str(page_id))\n",
    "        soup = BeautifulSoup(article.text, 'html.parser')\n",
    "        paragraphs = soup.findAll('p')\n",
    "        if len(paragraphs) >= 10:\n",
    "            good_id_list.append(page_id)\n",
    "            #id_list.append(page_id)    #for preservation of good_id_list\n",
    "            corpus = page_read(soup)\n",
    "            \n",
    "            #write each wikipedia article to its own file\n",
    "            with open(\"/users/markregalla/desktop/metis/Project4/WikiArticles/page_\" \n",
    "                      + str(page_id) + \".txt\", \"w\") as myfile:\n",
    "                myfile.write(corpus.encode(\"UTF-8\"))\n",
    "            myfile.close\n",
    "            counter += 1\n",
    "    i += 1\n",
    "    \n",
    "    #prints iterators as a status\n",
    "    sys.stdout.write(\"\\r\" + 'Attempts: ' + str(i) + '  Sucesses: ' + str(counter))   \n",
    "\n",
    "print '\\n' + str(len(good_id_list))\n",
    "#print '\\n' + str(len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dump list of good id nos into pickle file\n",
    "with open('paralist.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(good_id_list, picklefile)\n",
    "    pickle.dump(paralist, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#retrieve list of good id nos\n",
    "with open('good_id_list_1.pkl', 'r') as picklefile:\n",
    "    good_id_list = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#test scraping and appending to file\n",
    "useid = 1000076\n",
    "article = requests.get('https://en.wikipedia.org/?curid=1000076')# + str(useid))\n",
    "#article = requests.get('https://en.wikipedia.org/wiki/William_Cleland')\n",
    "soup = BeautifulSoup(article.text, 'html.parser')\n",
    "paragraphs = soup.findAll('p')\n",
    "print len(paragraphs)\n",
    "#corpus = page_read(soup)\n",
    "#f = open('output.txt', 'w')\n",
    "#simplejson.dump(corpus, f)\n",
    "#f.close()\n",
    "#with open(\"total_corpus.txt\", \"ab\") as myfile:\n",
    "#    myfile.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make webpage request\n",
    "#r = requests.get('https://en.wikipedia.org/w/api.php?action=query&meta=siteinfo&\\\n",
    "#                 format=json&siprop=namespaces&pageids=1200008')\n",
    "r = requests.get('https://en.wikipedia.org/w/api.php?action=query&prop=info\\\n",
    "                &format=json&inprop=url&pageids=1000001')#   + str(useid))\n",
    "#figure out what part of the returned json has the namespace data\n",
    "rtext = r.text\n",
    "jsontext = json.loads(rtext)\n",
    "print jsontext['query']['pages']['1000001']['ns']\n",
    "jsontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000003'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get article names from saved files in directory\n",
    "#good_id_list = []\n",
    "#for article in os.listdir('/users/markregalla/desktop/metis/Project4/WikiArticles'):\n",
    "#    good_id_list.append(article[5:12])\n",
    "good_id_list[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999CPU times: user 18.5 s, sys: 7.43 s, total: 25.9 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#url = ['https://en.wikipedia.org/wiki/Myocardial_infarction',\n",
    "#      'https://en.wikipedia.org/wiki/Blood_flow',\n",
    "#      'https://en.wikipedia.org/wiki/Circulatory_system#Human_cardiovascular_system']\n",
    "\n",
    "TaggedDocument = gensim.models.doc2vec.TaggedDocument\n",
    "u = 0\n",
    "model_list = []\n",
    "paralist = []\n",
    "\n",
    "#for loop for opening each file in directory for training\n",
    "for article in os.listdir('/users/markregalla/desktop/metis/Project4/WikiArticles'):\n",
    "    \n",
    "    #Open saved total_corpus file for training\n",
    "    with open(\"/users/markregalla/desktop/metis/Project4/WikiArticles/\" \n",
    "              + article, \"r\") as myfile:\n",
    "        para = myfile.read()\n",
    "    myfile.close\n",
    "    \n",
    "    para = [para]\n",
    "    para = cleanText(para)\n",
    "    paralist.append(para)\n",
    "    \n",
    "    sys.stdout.write(\"\\r\" + str(u))   #prints iterator as a status\n",
    "    u += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "paralist = labelizeReviews(paralist, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 57s, sys: 2.28 s, total: 15min 59s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wiki_model = gensim.models.Doc2Vec(paralist, size=100, window=8, min_count=5, workers=4)\n",
    "#print all_model.docvecs['Testing_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.68381736e-01,   7.26402923e-03,   2.74325311e-01,\n",
       "         1.21189214e-01,  -1.45054728e-01,   2.31232867e-01,\n",
       "         2.17188802e-02,   5.47457905e-03,   6.52274489e-02,\n",
       "        -1.65897071e-01,  -2.44385339e-02,  -3.40961735e-04,\n",
       "        -3.89444381e-02,   1.50435492e-01,   2.07790583e-01,\n",
       "        -2.10372031e-01,   1.02731302e-01,  -4.28983271e-01,\n",
       "        -1.42702730e-02,  -7.09153339e-02,  -3.73726413e-02,\n",
       "         1.37683868e-01,   1.92687050e-01,  -2.97558546e-01,\n",
       "         8.31312612e-02,   2.56571084e-01,  -3.51616219e-02,\n",
       "        -1.34719029e-01,  -2.08851829e-01,   2.99105227e-01,\n",
       "         3.57070602e-02,  -1.10025533e-01,   1.94865853e-01,\n",
       "         1.88904464e-01,   1.96980372e-01,  -2.34741569e-01,\n",
       "        -6.85167760e-02,  -8.82658809e-02,   9.62052792e-02,\n",
       "         3.76733631e-01,  -6.14120066e-02,  -3.18853855e-02,\n",
       "        -4.48924787e-02,   8.94338787e-02,  -1.27420127e-01,\n",
       "        -2.19222233e-01,  -2.33381778e-01,  -9.18921083e-02,\n",
       "         1.00206770e-01,  -2.22689867e-01,   1.54158309e-01,\n",
       "         4.53802943e-02,  -3.15427184e-01,   2.83399913e-02,\n",
       "        -6.47993907e-02,  -1.71904132e-01,   1.17704859e-02,\n",
       "         3.63815092e-02,  -6.14251904e-02,  -1.96618475e-02,\n",
       "        -1.33307979e-01,   6.41998798e-02,  -4.79689892e-03,\n",
       "        -1.70105949e-01,   1.63037673e-01,   4.48158273e-04,\n",
       "        -4.71093170e-02,  -9.00373387e-04,   1.22004673e-01,\n",
       "         4.01818007e-03,   1.67023435e-01,   1.01634236e-02,\n",
       "         1.77316263e-01,   3.64427865e-02,   1.50909558e-01,\n",
       "         1.56920806e-01,  -2.28615049e-02,  -3.21834922e-01,\n",
       "        -4.35031131e-02,   3.61038059e-01,  -1.27392352e-01,\n",
       "         2.00780444e-02,  -2.29738459e-01,  -2.00333372e-02,\n",
       "        -2.30892852e-01,   2.66841531e-01,  -3.88918966e-02,\n",
       "        -7.65022784e-02,  -8.98169875e-02,   5.49823105e-01,\n",
       "        -8.07110071e-02,  -8.39492381e-02,  -2.90924847e-01,\n",
       "        -5.19922040e-02,   2.14759000e-02,  -3.39639895e-02,\n",
       "        -4.44535092e-02,   2.35994741e-01,   4.06388044e-02,\n",
       "        -2.33802572e-01], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_model.docvecs['Testing_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -1.83365634e-03  -1.73638144e-03   2.20782799e-03   4.03400016e-04\n",
      "     4.01591184e-03  -2.66468967e-03  -2.61389744e-03  -5.09220362e-03\n",
      "    -2.22901767e-03  -3.46541638e-03   5.64583903e-03  -4.81759524e-03\n",
      "     2.93042324e-03  -3.12161539e-03  -2.42420778e-04  -4.89932671e-03\n",
      "    -3.95731814e-03   2.41178460e-03   2.31958716e-03   3.45026120e-03\n",
      "    -2.13622325e-03  -1.59452960e-04   4.32716729e-03  -4.05623158e-03\n",
      "     5.45282476e-03  -1.92154921e-03   3.67220986e-04   1.90681440e-03\n",
      "     3.01903603e-03  -2.20498885e-03  -4.47325176e-03   4.99932840e-03\n",
      "     2.24023149e-03   1.16491434e-03  -3.11132590e-03  -5.07642794e-03\n",
      "     4.54335939e-03  -4.28345101e-03   5.54758357e-03  -1.14266691e-03\n",
      "    -1.77977374e-03  -5.49554173e-03  -3.03486537e-04   7.44599616e-04\n",
      "    -7.36039481e-04  -1.27591437e-03   2.20247987e-03   1.84075686e-03\n",
      "     3.70729668e-03  -3.77933099e-03   1.30712963e-03   4.41066828e-03\n",
      "    -8.34574574e-04   3.38809285e-03   3.71214864e-03   1.04800356e-03\n",
      "     4.33748029e-03  -1.74557010e-03   6.48151501e-04  -2.41719186e-03\n",
      "    -1.24275498e-03   1.79376407e-03  -4.77058208e-03   5.64909024e-05\n",
      "     1.56508642e-03   4.86643286e-03   1.21536272e-04  -9.24848951e-04\n",
      "     2.93561630e-03   2.36139307e-03   4.75441664e-03   1.52722083e-03\n",
      "    -5.09426137e-03  -5.54327946e-03  -3.12743313e-03  -4.86061024e-03\n",
      "     4.91782278e-03   2.74685817e-03   1.30057262e-04  -1.44924340e-03\n",
      "     5.26092900e-03   2.95664777e-05   6.81290927e-04  -1.85348603e-04\n",
      "     1.57265784e-03   3.90277291e-03  -5.51839406e-03   4.19844501e-03\n",
      "    -5.36505412e-03   1.44173007e-03   1.69519009e-03  -3.11367936e-03\n",
      "    -1.77356345e-03   4.14979830e-03   5.49382111e-03  -1.36126054e-03\n",
      "     1.43546599e-03   4.04422637e-03  -1.61357305e-03  -2.71425489e-03\n",
      "    -5.28612360e-03   6.43934647e-04   1.28948489e-06  -3.67966457e-03\n",
      "     5.40180271e-03  -4.97973291e-03  -4.65127407e-03   5.16094500e-03\n",
      "     1.21754711e-03   5.75456675e-03  -9.40315542e-04  -1.44469319e-03\n",
      "    -2.92672939e-03   1.85685625e-04   1.61677890e-03  -1.24007347e-03\n",
      "     4.29345248e-03   4.60568210e-03  -4.17648396e-03   3.14571476e-03\n",
      "     1.29668799e-03   1.75273803e-03   2.65822187e-03   3.35339690e-03\n",
      "     3.90151958e-03   1.10148196e-03  -2.42907554e-03   3.14578181e-03\n",
      "     2.46803183e-03   2.07765051e-03  -1.11575134e-03  -4.78699757e-03\n",
      "    -2.19884352e-03  -4.71325452e-03  -2.22271821e-03   2.41167960e-03\n",
      "     5.61226532e-03   3.70945944e-03  -1.66267983e-03  -2.81875744e-03\n",
      "    -3.05466121e-03  -1.96544570e-03  -1.53005414e-03   4.45753848e-03\n",
      "    -9.82060330e-04   3.05232196e-03   2.28285324e-03  -2.61405227e-03\n",
      "    -3.11318552e-03  -5.86710812e-04   4.19955654e-03   1.33056031e-03\n",
      "    -4.61380044e-03   1.34488349e-04  -4.99987369e-03  -5.56811457e-03\n",
      "    -2.35324143e-03   2.01420020e-03  -5.15177567e-03   5.49186859e-03\n",
      "     4.25735401e-04  -2.72692274e-03   4.73805144e-03  -3.66875622e-03\n",
      "     5.02031017e-03  -3.18029127e-03   1.71132258e-03  -1.52445619e-03\n",
      "     4.79046954e-03  -3.67131986e-04  -1.55096781e-03   1.69621571e-03\n",
      "     5.71031310e-03  -3.68154561e-03   4.11461014e-03  -3.60751711e-03\n",
      "     1.50136522e-03  -5.22938417e-03  -5.80308307e-03  -1.50571240e-03\n",
      "    -2.33971211e-03   8.50000943e-04  -8.71878641e-04   4.19169478e-03\n",
      "     1.54896581e-03   4.27602883e-03  -4.10364242e-03  -1.12999766e-03\n",
      "     4.29204339e-03   2.28535919e-03   7.74146116e-04   3.14352728e-05\n",
      "    -6.80042780e-04   2.36839638e-03   2.29343446e-03  -1.92782690e-03\n",
      "    -1.96933444e-03  -2.33261869e-03  -2.85354001e-03   3.27177625e-03]]\n",
      "\n",
      " [[ -8.40425678e-03  -7.95840658e-03   1.01191858e-02   1.84891594e-03\n",
      "     1.84062812e-02  -1.22131621e-02  -1.19803520e-02  -2.33392660e-02\n",
      "    -1.02163609e-02  -1.58831868e-02   2.58768611e-02  -2.20806561e-02\n",
      "     1.34311011e-02  -1.43074160e-02  -1.11109437e-03  -2.24551577e-02\n",
      "    -1.81376562e-02   1.10540278e-02   1.06314309e-02   1.58136599e-02\n",
      "    -9.79103986e-03  -7.30825705e-04   1.98328402e-02  -1.85910556e-02\n",
      "     2.49921158e-02  -8.80710874e-03   1.68309698e-03   8.73955805e-03\n",
      "     1.38372285e-02  -1.01062153e-02  -2.05023866e-02   2.29135584e-02\n",
      "     1.02677094e-02   5.33917733e-03  -1.42602716e-02  -2.32669394e-02\n",
      "     2.08237320e-02  -1.96324848e-02   2.54264362e-02  -5.23720542e-03\n",
      "    -8.15731473e-03  -2.51878817e-02  -1.39097951e-03   3.41274566e-03\n",
      "    -3.37351649e-03  -5.84794674e-03   1.00946976e-02   8.43679346e-03\n",
      "     1.69917531e-02  -1.73219256e-02   5.99101977e-03   2.02155150e-02\n",
      "    -3.82512319e-03   1.55287962e-02   1.70139931e-02   4.80335485e-03\n",
      "     1.98801421e-02  -8.00053310e-03   2.97069363e-03  -1.10787861e-02\n",
      "    -5.69595769e-03   8.22141301e-03  -2.18651239e-02   2.58916669e-04\n",
      "     7.17330584e-03   2.23044474e-02   5.57040796e-04  -4.23888816e-03\n",
      "     1.34549178e-02   1.08230887e-02   2.17910409e-02   6.99976226e-03\n",
      "    -2.33486965e-02  -2.54066829e-02  -1.43340621e-02  -2.22777706e-02\n",
      "     2.25399844e-02   1.25897648e-02   5.96096623e-04  -6.64237607e-03\n",
      "     2.41126064e-02   1.35512950e-04   3.12258326e-03  -8.49514676e-04\n",
      "     7.20801763e-03   1.78877227e-02  -2.52927076e-02   1.92428418e-02\n",
      "    -2.45898385e-02   6.60793204e-03   7.76962424e-03  -1.42710162e-02\n",
      "    -8.12881719e-03   1.90199483e-02   2.51800232e-02  -6.23909943e-03\n",
      "     6.57921936e-03   1.85360517e-02  -7.39555294e-03  -1.24403192e-02\n",
      "    -2.42280494e-02   2.95137265e-03   5.91014896e-06  -1.68651249e-02\n",
      "     2.47582365e-02  -2.28237621e-02  -2.13183910e-02   2.36543603e-02\n",
      "     5.58042154e-03   2.63751950e-02  -4.30977717e-03  -6.62150932e-03\n",
      "    -1.34141715e-02   8.51060206e-04   7.41023710e-03  -5.68368658e-03\n",
      "     1.96783133e-02   2.11094022e-02  -1.91422366e-02   1.44179063e-02\n",
      "     5.94316283e-03   8.03340133e-03   1.21835247e-02   1.53697496e-02\n",
      "     1.78819541e-02   5.04844775e-03  -1.11332703e-02   1.44181475e-02\n",
      "     1.13118086e-02   9.52258799e-03  -5.11385454e-03  -2.19403915e-02\n",
      "    -1.00780288e-02  -2.16024313e-02  -1.01874731e-02   1.10535445e-02\n",
      "     2.57228892e-02   1.70016550e-02  -7.62060704e-03  -1.29193207e-02\n",
      "    -1.40005574e-02  -9.00832564e-03  -7.01275840e-03   2.04303805e-02\n",
      "    -4.50110808e-03   1.39898043e-02   1.04630766e-02  -1.19810943e-02\n",
      "    -1.42687652e-02  -2.68908963e-03   1.92479845e-02   6.09839568e-03\n",
      "    -2.11465657e-02   6.16404461e-04  -2.29160469e-02  -2.55205669e-02\n",
      "    -1.07856877e-02   9.23175458e-03  -2.36122683e-02   2.51710918e-02\n",
      "     1.95128715e-03  -1.24984086e-02   2.17161588e-02  -1.68150924e-02\n",
      "     2.30097324e-02  -1.45763541e-02   7.84355495e-03  -6.98708929e-03\n",
      "     2.19563358e-02  -1.68269104e-03  -7.10860593e-03   7.77431624e-03\n",
      "     2.61723287e-02  -1.68737583e-02   1.88586283e-02  -1.65344849e-02\n",
      "     6.88127242e-03  -2.39680037e-02  -2.65974849e-02  -6.90117339e-03\n",
      "    -1.07236905e-02   3.89583386e-03  -3.99610354e-03   1.92118920e-02\n",
      "     7.09977280e-03   1.95993185e-02  -1.88092515e-02  -5.17939869e-03\n",
      "     1.96727794e-02   1.04750451e-02   3.54833296e-03   1.44084755e-04\n",
      "    -3.12106148e-03   1.08697591e-02   1.05257127e-02  -8.84777866e-03\n",
      "    -9.03827418e-03  -1.07055502e-02  -1.30963111e-02   1.50158349e-02]]]\n"
     ]
    }
   ],
   "source": [
    "concat_model = ConcatenatedDoc2Vec([x for x in model_list])\n",
    "print concat_model.docvecs['Testing_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/s,d200,hs,w8,mc5,t4)\n",
      "{'vocab': 7700, 'doctag_lookup': 200, 'doctag_syn0': 800, 'total': 26300, 'syn0': 8800, 'syn1': 8800}\n"
     ]
    }
   ],
   "source": [
    "#find difference bewteen instantiating model, then building model\n",
    "model = gensim.models.Doc2Vec(size=200, window=8, min_count=5, workers=4)\n",
    "model.build_vocab(para)\n",
    "print model\n",
    "print model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/s,d200,hs,w8,mc5,t4)\n",
      "{'vocab': 7700, 'doctag_lookup': 200, 'doctag_syn0': 800, 'total': 26300, 'syn0': 8800, 'syn1': 8800}\n"
     ]
    }
   ],
   "source": [
    "#or just running text through gensim model\n",
    "model = gensim.models.Doc2Vec(para, size=200, window=8, min_count=5, workers=4)\n",
    "print model\n",
    "print model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method to scrape each wikipedia article and concatenate model\n",
    "#Not a functioning strategy yet\n",
    "\n",
    "while u < 2:\n",
    "    Scrape page to get data for training\n",
    "    response = requests.get('https://en.wikipedia.org/?curid=' + str(good_id_list[u]))\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    para = page_read(soup)\n",
    "\n",
    "    model = gensim.models.Doc2Vec(para, size=200, window=8, min_count=5, workers=4)\n",
    "    model_list.append(model)\n",
    "    print model.docvecs['Testing_' + str(u)]\n",
    "    model.build_vocab(para)\n",
    "    model.sort_vocab()\n",
    "    model.train(para)\n",
    "    print model\n",
    "    print model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def page_read(soup):\n",
    "    #thetext = []\n",
    "    thetext = ''\n",
    "    paragraphs = soup.findAll('p') #comment out only for when saving wiki articles to disk\n",
    "    for p in paragraphs:\n",
    "        #thetext.append(p.text)    #make a list of sentences\n",
    "        thetext = thetext + p.text + '\\n' #make a list with 1 element being the whole document\n",
    "    #thetext = [thetext]\n",
    "    #theindex = 0\n",
    "    #wikidef = paragraphs[theindex].text\n",
    "    #print thetext\n",
    "    #print type(thetext)\n",
    "    return thetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(corpus):\n",
    "    corpus = [z.lower() for z in corpus]\n",
    "    corpus = re.sub('\\n', ' ', corpus[0])\n",
    "    corpus = re.sub('\\\\[.*?\\\\]',' ', corpus)\n",
    "    \n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    #punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    #for c in punctuation:\n",
    "    #    corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    #corpus = [z.split() for z in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelizeReviews(reviews, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        #label = '%s_%s'%(label_type,i)    #iterate sentence labels\n",
    "        label = '%s_%s'%(label_type,1)     #uniform sentence labels\n",
    "        labelized.append(TaggedDocument(v, [label]))\n",
    "    return labelized\n",
    "    #yield LabeledSentence(words=line.split(), labels=['SENT_%s' % uid])\n",
    "        #yield gensim.models.doc2vec.LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-5f1a16bb4282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"This is a sentence\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"This is another sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, dm, hs, negative, dbow_words, dm_mean, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, keep_raw_vocab, trim_rule)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# initial survey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# trim by min_count & precalculate downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build tables & arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0minterval_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0minterval_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mdocument_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "doc1=[\"This is a sentence\",\"This is another sentence\"]\n",
    "documents=[doc.strip().split(\" \") for doc in doc1 ]\n",
    "model = gensim.models.Doc2Vec(documents, size = 100, window = 300, min_count = 10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-66e7d514b1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m texts = [[word for word in document.lower().split() if word not in stoplist]\n\u001b[1;32m     12\u001b[0m         for document in documents]\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, dm, hs, negative, dbow_words, dm_mean, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, keep_raw_vocab, trim_rule)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# initial survey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# trim by min_count & precalculate downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build tables & arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markregalla/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0minterval_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0minterval_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mdocument_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "            \"A survey of user opinion of computer system response time\",\n",
    "            \"The EPS user interface management system\",\n",
    "            \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in documents]\n",
    "model = gensim.models.Doc2Vec(texts, size = 100, window = 300, min_count = 10, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
